{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T19:33:41.529899Z",
     "start_time": "2020-08-16T19:33:33.089989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AW639XJ\\.conda\\envs\\ey-hindalco-env\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_iris\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seeds = 42\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"mark\">Correlation Diagram</span>\n",
    "<img src = 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/600px-Correlation_examples2.svg.png' > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T18:35:58.535248Z",
     "start_time": "2020-08-15T18:35:58.527815Z"
    }
   },
   "source": [
    "# <span class=\"mark\">Pearson Correlation Formula</span> : \n",
    "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/f76ccfa7c2ed7f5b085115086107bbe25d329cec'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T19:55:48.238838Z",
     "start_time": "2020-08-16T19:55:48.183813Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sample_data(boston,iris,normal,**kwargs):\n",
    "    \"\"\" Attributes:\n",
    "            boston = True; For loading Boston Dataset with MEDV as the target and other columns as the input dataset.\n",
    "            iris = True; For loading Iris Dataset with Class as the target and other columns as the input dataset.\n",
    "            normal = True; For loading Regression Dataset with specified samples, features, informative_features\n",
    "            Kwargs = n_samples, n_features, n_informative , None\n",
    "        \n",
    "        Defaults:\n",
    "            n_samples=100, n_features=100, n_informative=10\n",
    "    \"\"\"\n",
    "    if boston:\n",
    "        x = load_boston()\n",
    "        df = pd.DataFrame(x.data, columns = x.feature_names)\n",
    "        df[\"MEDV\"] = x.target\n",
    "        X = df.drop(\"MEDV\",1)   \n",
    "        y = df[\"MEDV\"]\n",
    "        \n",
    "    elif iris:\n",
    "        iris = load_iris()\n",
    "        X = iris.data\n",
    "        y = iris.target\n",
    "        class_names = iris.target_names\n",
    "        X = pd.DataFrame(X,columns=iris.feature_names)\n",
    "        y = pd.DataFrame(y,columns=['Class'])\n",
    "#         pd.concat([X,y],axis=1).to_csv(\"Trial_Dataset.csv\")\n",
    "    elif normal:\n",
    "        if kwargs.items():\n",
    "            params = [v for k,v in kwargs.items()]\n",
    "            X, y = make_regression(n_samples=params[0], n_features=params[1], n_informative=params[2])\n",
    "            X = pd.DataFrame(X)\n",
    "            y = pd.DataFrame(y,columns=['Class'])\n",
    "        else:\n",
    "            X, y = make_regression(n_samples=100, n_features=100, n_informative=10)\n",
    "            X = pd.DataFrame(X)\n",
    "            y = pd.DataFrame(y,columns=['Class'])\n",
    "    else:\n",
    "        print(\"No dataset Loaded\")\n",
    "    return X,y\n",
    "\n",
    "def cal_pearson_coef(X,show_map,save_map):\n",
    "    \"\"\" Attributes:\n",
    "            X = dataframe for calculating squared pearson matrix.\n",
    "            show_map = plot the pearson correlation heatmap via matplotlib and sns.\n",
    "            save_map = save the pearson correlation heat map in png format.\n",
    "    \"\"\"\n",
    "    pears_cor = X.corr().abs()\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(pears_cor, annot=True, cmap=plt.cm.Reds)\n",
    "    if save_map:\n",
    "        plt.savefig('Pearson_Correlation_Heatmap.png')\n",
    "    if show_map:\n",
    "        plt.show()\n",
    "    pears_cor.to_csv('Pearson_Correlation.csv',index=False)\n",
    "    plt.close()\n",
    "    return pears_cor\n",
    "\n",
    "def drop_corr_cols(X, THRESH=0.85,show_map=True,save_map=True):\n",
    "    \"\"\" Attributes:\n",
    "        X = Dataset of features (without labels)\n",
    "        THRESH = Threshold to neglect dependent features and make less complex model.\n",
    "        show_map = plot the pearson correlation heatmap via matplotlib and sns.\n",
    "        save_map = save the pearson correlation heat map in png format.\n",
    "\n",
    "        Defaults:\n",
    "            THRESH = 0.85\n",
    "            show_map = True\n",
    "            save_map = True\n",
    "    \"\"\"\n",
    "    n_col = len(X.columns)\n",
    "    corr_matrix = cal_pearson_coef(X,show_map,save_map)\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),\n",
    "                                      k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > THRESH)]\n",
    "    print(\"Following columns are dropped:\",to_drop)\n",
    "    # Drop Marked Features\n",
    "    X_N = X.drop(columns = to_drop)\n",
    "    if len(to_drop) <= n_col // 2:\n",
    "        return X_N\n",
    "    elif abs(len(to_drop) - n_col) == 0:\n",
    "        return X\n",
    "    elif len(to_drop) > n_col // 2:\n",
    "        return X_N\n",
    "\n",
    "def drop_multiple_col(col_names_list, df): \n",
    "    \"\"\"Drop multiple columns based on their column names \n",
    "    Attributes: List of column names, df\n",
    "    \"\"\"\n",
    "    df.drop(col_names_list, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def change_dtypes(col_int, col_float, df): \n",
    "    \"\"\"Changing dtypes to save memory\n",
    "    Attributes: List of column names (int, float), df\n",
    "    \"\"\"\n",
    "    if len(col_int) > 0:\n",
    "        for c in col_int:\n",
    "            df[c] = df[c].astype('int32')\n",
    "    if len(col_float) > 0:\n",
    "        for c in col_float:\n",
    "            df[c] = df[c].astype('float32')\n",
    "    return df\n",
    "\n",
    "def check_missing_data(df):\n",
    "    \"\"\"check for any missing data in the df (display in descending order)\"\"\"\n",
    "    if df.isnull().sum().sort_values(ascending=False).sum() == 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return df.isnull().sum().sort_values(ascending=False)\n",
    "    \n",
    "def remove_col_str(df,str_cols):\n",
    "    if len(str_cols) > 0:\n",
    "        for c in str_cols:\n",
    "            # remove a portion of string in a dataframe column - col_1\n",
    "            df[c].replace('\\n', '', regex=True, inplace=True)\n",
    "            # remove all the characters after &# (including &#) for column - col_1\n",
    "            df[c].replace(' &#.*', '', regex=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def remove_col_white_space(df,col):\n",
    "    for i in col:\n",
    "        df[i] = df[i].str.lstrip()\n",
    "    return df\n",
    "\n",
    "def convert_str_datetime(t): \n",
    "    return pd.to_datetime(t,dayfirst=True,format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "def clean_dataframe(df,**kwargs):\n",
    "    \"\"\"cleaning dataframe : \n",
    "    df : Dataframe to be cleaned.\n",
    "    ne_cols : Primary Columns which can't be empty/NA.\n",
    "    date_cols: Date columns to be formatted to particular format.\n",
    "    str_cols: String columns\n",
    "    drop_cols: Useless Columns \n",
    "    col_int: Integer Columns\n",
    "    col_float: Float Columns\n",
    "    \"\"\"\n",
    "    ne_cols,date_cols,str_cols,col_int,col_float,drop_cols = kwargs['ne_cols'],kwargs['date_cols'],kwargs['str_cols'],kwargs['col_int'],kwargs['col_float'],kwargs['drop_cols']\n",
    "    if len(str_cols) > 0:\n",
    "        df = remove_col_str(df,str_cols)\n",
    "    if len(drop_cols) > 0:\n",
    "        df =  drop_multiple_col(drop_cols,df)\n",
    "    if len(ne_cols) > 0:\n",
    "        df = df.dropna(subset=ne_cols)\n",
    "    if len(str_cols) > 0:\n",
    "        df = remove_col_white_space(df,str_cols)\n",
    "    if len(date_cols) > 0:\n",
    "        for dt in date_cols:\n",
    "            df[dt] = df[dt].apply(convert_str_datetime)\n",
    "    print(\"Missing Data:\",check_missing_data(df))\n",
    "    if len(col_int) > 0 or len(col_float) > 0:\n",
    "        df = change_dtypes(col_int, col_float, df)\n",
    "    return df\n",
    "\n",
    "def specify_cols(df):\n",
    "    print(\"Specify String,Not null,Integer,Float and Date Columns with following flags: \\n 1. I: for int \\n 2. S: for string \\n 3. F: float \\n 4. D: Date \\n 5.N: Columns should not be Null.\")\n",
    "    ne_cols = []\n",
    "    date_cols = []\n",
    "    str_cols = []\n",
    "    col_int = []\n",
    "    col_float = []\n",
    "    drop_cols = []\n",
    "    for c in df.columns:\n",
    "        print(f'For column {c} : ')\n",
    "        chc = input('Input Column Type: ')\n",
    "        if chc.lower() == 'i':\n",
    "            col_int.append(c)\n",
    "        elif chc.lower() == 's':\n",
    "            str_cols.append(c)\n",
    "        elif chc.lower() == 'f':\n",
    "            col_float.append(c)\n",
    "        elif chc.lower() == 'd':\n",
    "            date_cols.append(c)\n",
    "        elif chc.lower() == 'n':\n",
    "            ne_cols.append(c)\n",
    "        else:\n",
    "            print('Wrong choice')\n",
    "            continue\n",
    "    print(\"Specify Columns to be dropped: \\n 1. Yes: To drop column from Dataset \\n 2. No: To keep column in dataset\")\n",
    "    for c in df.columns:\n",
    "        chc = input(f'Do you want to drop {c}: Yes/No: ')\n",
    "        if chc.lower() == 'yes' or chc.lower() == 'y':\n",
    "            drop_cols.append(c)\n",
    "        elif chc.lower() == 'no' or chc.lower() == 'n':\n",
    "            pass\n",
    "        else:\n",
    "            print('Wrong choice')\n",
    "            continue\n",
    "    return ne_cols,date_cols,str_cols,col_int,col_float,drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T20:10:27.321561Z",
     "start_time": "2020-08-16T20:10:27.291555Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" Choose any one default load_data or load new file (.csv or .xlsx):\n",
    "        1. Create new Regression dataset\n",
    "        2. Iris\n",
    "        3. Boston\n",
    "    \"\"\"\n",
    "    chc = str(input('Do you want default Dataset? : Yes/No - '))\n",
    "    if chc.lower() == 'yes' or chc.lower() == 'y':\n",
    "        print(\"------ Default Dataset -----\")\n",
    "        print(\"Chose any one load_data options : \\n 1. Create new Regression dataset \\n 2. Iris \\n 3. Boston\")\n",
    "        val = int(input('Please enter choice: '))\n",
    "        if val == 1:\n",
    "            X,y = load_sample_data(boston=False,iris=False,normal=True,n_samples=100, n_features=10, n_informative=5)\n",
    "        elif val == 2:\n",
    "            X,y = load_sample_data(boston=False,iris=True,normal=False)\n",
    "        else:\n",
    "            X,y = load_sample_data(boston=True,iris=False,normal=False)\n",
    "\n",
    "    elif chc.lower() == 'no' or chc.lower() == 'n':\n",
    "        print(\"------ Non Default Dataset -----\")\n",
    "        f_name = str(input(r'Please enter filename with directory without start and end quotes: For eg : C:\\Users\\ABC\\Downloads\\Kaggle\\Data_0.013_20200807_040358.csv'))\n",
    "        assert os.path.exists(f_name), \"File doesn't exist at - \"+f_name+\" or Directory doesn't exist. Please check!!\"\n",
    "        _ext = os.path.splitext(f_name)[1]\n",
    "        if _ext == '.csv' or _ext =='.txt':\n",
    "            df = pd.read_csv(os.path.join(f_name))\n",
    "        elif _ext == '.xlsx':\n",
    "            sname = str(input('Please enter sheet_name: '))\n",
    "            if sname:\n",
    "                df = pd.read_excel(os.path.join(f_name),sheet_name = sname)\n",
    "            df = pd.read_excel(os.path.join(f_name))\n",
    "        else:\n",
    "            print(\"File has unidentified extension.\")\n",
    "            exit()\n",
    "        print('Data Loaded Successfully! \\n ----------------------------------------- \\n')\n",
    "        chc = input('Does you data consist labels? Yes/No')\n",
    "        if chc.lower() == 'no' or chc.lower() == 'n':\n",
    "            X = df\n",
    "            ne_cols,date_cols,str_cols,col_int,col_float,drop_cols = specify_cols(X)\n",
    "            X = clean_dataframe(X,ne_cols=ne_cols,date_cols=date_cols,str_cols=str_cols,\n",
    "                                drop_cols=drop_cols,col_int=col_int,col_float=col_float)\n",
    "\n",
    "        elif chc.lower() == 'yes' or chc.lower() == 'y':\n",
    "            target_col = input('Please provide Target Column in the given file - ')\n",
    "            y = df[target_col]\n",
    "            X = df.drop(columns= [target_col]).reset_index(drop=True)\n",
    "            ne_cols,date_cols,str_cols,col_int,col_float,drop_cols = specify_cols(X)\n",
    "            X = clean_dataframe(X,ne_cols=ne_cols,date_cols=date_cols,str_cols=str_cols,\n",
    "                                drop_cols=drop_cols,col_int=col_int,col_float=col_float)\n",
    "\n",
    "        else:\n",
    "            print(\"No such option available.\")\n",
    "            exit()\n",
    "    else:\n",
    "        print(\"No such option available.\")\n",
    "        exit()\n",
    "    \n",
    "    THRESH = float(input('Please enter threshold for Pearson Coeffecient to reject the correalated variables: '))\n",
    "    chc1 = input('Do you want to save correlation graphs? Yes/No- ')\n",
    "    chc = input('Do you want to show correlation graphs? Yes/No- ')\n",
    "    if chc.lower() == 'no' or chc.lower() == 'n':\n",
    "        show_flag = False\n",
    "    elif chc.lower() == 'yes' or chc.lower() == 'y':\n",
    "        show_flag = True\n",
    "    else:\n",
    "        print(\"No such option available.\")\n",
    "        exit()\n",
    "    if chc1.lower() == 'no' or chc1.lower() == 'n':\n",
    "        save_flag = False\n",
    "    elif chc1.lower() == 'yes' or chc1.lower() == 'y':\n",
    "        save_flag = True\n",
    "    else:\n",
    "        print(\"No such option available.\")\n",
    "        exit()\n",
    "    print(\"Earlier Variables were: \",X.columns)\n",
    "    new_df = drop_corr_cols(X,THRESH,show_flag,save_flag)\n",
    "    print('Selected Variables after rejecting via pearson correlation are :',new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T20:11:05.962905Z",
     "start_time": "2020-08-16T20:10:28.406636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want default Dataset? : Yes/No - n\n",
      "------ Non Default Dataset -----\n",
      "Please enter filename with directory without start and end quotes: For eg : C:\\Users\\ABC\\Downloads\\Kaggle\\Data_0.013_20200807_040358.csvC:\\Users\\AW639XJ\\Downloads\\Nachi's Interview code\\Trial_Dataset.csv\n",
      "Data Loaded Successfully! \n",
      " ----------------------------------------- \n",
      "\n",
      "Does you data consist labels? Yes/Noy\n",
      "Please provide Target Column in the given file - Class\n",
      "Specify String,Not null,Integer,Float and Date Columns with following flags: \n",
      " 1. I: for int \n",
      " 2. S: for string \n",
      " 3. F: float \n",
      " 4. D: Date \n",
      " 5.N: Columns should not be Null.\n",
      "For column sepal length (cm) : \n",
      "Input Column Type: f\n",
      "For column sepal width (cm) : \n",
      "Input Column Type: f\n",
      "For column petal length (cm) : \n",
      "Input Column Type: f\n",
      "For column petal width (cm) : \n",
      "Input Column Type: f\n",
      "Specify Columns to be dropped: \n",
      " 1. Yes: To drop column from Dataset \n",
      " 2. No: To keep column in dataset\n",
      "Do you want to drop sepal length (cm): Yes/No: n\n",
      "Do you want to drop sepal width (cm): Yes/No: n\n",
      "Do you want to drop petal length (cm): Yes/No: n\n",
      "Do you want to drop petal width (cm): Yes/No: n\n",
      "Missing Data: 0\n",
      "Please enter threshold for Pearson Coeffecient to reject the correalated variables: 0.85\n",
      "Do you want to save correlation graphs? Yes/No- n\n",
      "Do you want to show correlation graphs? Yes/No- n\n",
      "Earlier Variables were:  Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)'],\n",
      "      dtype='object')\n",
      "Following columns are dropped: ['petal length (cm)', 'petal width (cm)']\n",
      "Selected Variables after rejecting via pearson correlation are : Index(['sepal length (cm)', 'sepal width (cm)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# C:\\Users\\AW639XJ\\Downloads\\Nachi's Interview code\\Trial_Dataset.csv\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span class=\"burk\">Read Doc</span>: \n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html\n",
    "3. https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
    "4. https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "5. https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
